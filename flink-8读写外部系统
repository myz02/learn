--应用的一致性保障
 flink可以通过检查点保证应用内部的一致性，但是无法保证端到端的一致性保证，如果应用恢复最新一次检查点，那检查点之后处理的事件就可能重复处理
  --幂等性写
      多次操作但是只产生一次结果，同样的key插入MySQL，MySQL要求主键唯一，所以后续的同样key插入操作都会失败
  --事务性写
      基本思路就是，上次成功的检查点的事件才会被写入。
      flink提供了两个构件来实现数据汇连接器，一个通用的WAL数据汇和一个2PC数据汇
      --wal数据汇
          会将所有的数据提交到应用状态，在收到检查点通知后将它们发送到数据汇系统，无法保证100%精准一次性，接收系统需要处理一次次波峰式写入
      --2PC数据汇
          需要接收系统支持事务或提供可用来模拟事务的构件。
          每次生成检查点，会开启一次事务并将收到的事件附加到事务中，将收集到的事件写入到接收系统，但是不提交事务，等收到检查点完成通知再去提交事务
          
--自定义数据源函数
 --flink提供了两个接口和对应的富函数接口
     SourceFunction和RichSourceFunction用于定义非并行的数据源连接器，只能以单任务运行
     ParallelSourceFunction和RichParallelSourceFunction定义能够同时运行多个任务示例的数据源连接器
     都提供了open() close() run() cancel()
     run()负责执行具体的任务读取或接收工作  它会将这些记录传入到flink应用中，根据上游不同的系统，数据可能以推或拉的形式获取。
      run()只会在flink中调用一次，后者会专门为它开一个线程，该线程会不断循环读取或接收数据源的数据并发出。
     cancel()会在应用关闭时调用，run()方法会在cancel调用后立即终止。
          
--重放数据源
   如文件流可以提供文件流读取的偏移、kafka可提供主题下每个分区的偏移地址，并允许设置分区读取位置
   检查点持久化所有当前读取的位置，故障恢复时会读取偏移量，如果在没状态情况下启动，读取偏移需要被设成默认值，可重置数据源函数需要时间checkpointfunction接口
    并将读取偏移和相关元数据信息存入算子列表状态或算子联合列表状态中。
   必须要保证单独线程运行的sourcefunction.run()不会在检查点过程中向前推送偏移量和数据，为此可以sourcecontext.getcheckpointLock方法获取锁对象
   ```synchronized (sourceContext.getCheckpointLock()) {//具体的读取数据源的实现}

--数据源函数、时间戳和水位线
   sourceContext提供了两个方法：sourceContext.collectWithTimestamp(O,L)  和  sourceContext.emitWatermark(Watermark)
     collectWithTimestamp用来发出记录和与之关联的时间戳
     emitWatermark用来发出传入的水位线
   如果数据源并行度为2，要读取kafka的6个分区，每个并行度要去读取3个分区，混合数据记录可能导致事件时间戳进一步延迟，从而产生更多的迟到记录
   为了避免这种情况可以每个数据流分区独立生成水位线，将它们中最小值作为数据流的水位线发出，这样可以利用分区内有序，避免不必要的迟到数据
   但是实例一旦空闲下来，就有可能阻碍全局水位线前进，若是收不到输入记录，就不会发出新的水位线（应用中引入shuffle操作如keyby和rebalance等单个算子水位线停滞会导致应用停止工作）
   flink提供了一个机制将数据源函数标记为暂时空闲，flink的水位线机制会忽略掉所有空闲数据流分区，数据流开始接收记录就会恢复活动状态
   ```sourceContext.markAsTemporarilyIdle(); //将数据源函数标记为暂时空闲
