spark-广播变量
将数据发送个各个executor一份，使用的比特协议（人人为我我为人人，把数据分块，如果其中某个executor有块1，需要块1的executor都可以找它要）
实现map join的方式（广播变量。缓存文件(sc.addfile)。闭包）
闭包是每个task都是复制一份

rdd的五大属性
 1.compute()      描述本rdd的数据是怎么被计算出来的
 2.依赖rdd列表     存储本rdd依赖的一个或多个rdd
 3.分区列表        对数据进行切片
 4.[可选]分区器
 5.[可选]每个分区首选的计算执行位置

rdd是什么：弹性分布式数据集，是个数据集但是里面没有数据，想要获取它代表的数据就去调分区器
为什么是懒加载：转换算子就是调用父rdd的迭代器生成一个新的迭代器，只有行动算子才回去遍历迭代器

Dependency依赖关系
用会触发shuffle的算子一定会触发一个宽依赖吗，比如reducebykey
    val rdd4: RDD[(String, Int)] = rdd3.partitionBy(new HashPartitioner(3))
    val rdd5: RDD[(String, Int)] = rdd4.reduceByKey(_ + _, 3)
先根据hash进行分区，再调用reducebykey(默认用hash分区),这样就完全没有必要再触发shuffle,rdd4和rdd5都会在同一份stage中

默认分区 ：spark.default.parallelism优先级最高
 local模式下：总核数，最低为1
 分布式模式下：总核数，最低为2
 数据源的分区数看数据源读取器
 有默认分区数参数就用参数，没有就用上游rdd的最大分区数

默认分区器策略：
 如果存在拥有分区器的父rdd & （父rdd中的最大分区数/父rdd中的最大分区器的分区数<10倍 || 默认分区数<=最大分区器的分区数）
  就用上游最大分区器作为子RDD的分区器
  否则创建一个hashpartitioner分区器，分区数=默认分区数
 
